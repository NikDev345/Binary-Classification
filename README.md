ğŸ’³ Credit Card Fraud Detection
Binary Classification using Machine Learning
ğŸ“Œ Project Overview

Credit card fraud is a serious financial problem where fraudulent transactions cause significant losses to both customers and banks.
This project focuses on building a binary classification machine learning model that can identify whether a credit card transaction is fraudulent or legitimate.

The project demonstrates how machine learning models behave on highly imbalanced real-world datasets and why accuracy alone is not a reliable metric.

ğŸ¯ Problem Statement

Given a dataset of credit card transactions, the goal is to classify each transaction into one of two classes:

0 â†’ Legitimate Transaction

1 â†’ Fraudulent Transaction

This is a binary classification problem.

ğŸ“Š Dataset Information

Dataset Name: Credit Card Fraud Detection

Source: Kaggle

File Name: creditcard.csv

Total Transactions: ~284,000

Fraud Cases: ~492 (highly imbalanced dataset)

ğŸ”¹ The dataset contains anonymized features (V1 to V28) generated using PCA, along with:

Amount â†’ Transaction amount

Class â†’ Target label (0 or 1)

ğŸ“¥ Dataset Download Instructions

Visit Kaggle

Search for â€œCredit Card Fraud Detectionâ€

Download the dataset

Place the file as:

data/creditcard.csv

ğŸ§  Machine Learning Approach
âœ” Type of Learning

Supervised Learning

âœ” Problem Type

Binary Classification

âœ” Model Used

Logistic Regression (baseline model)

âœ” Key Challenge

Severe class imbalance

Fraud transactions are extremely rare compared to legitimate ones

âš™ï¸ Project Workflow

Load and inspect the dataset

Analyze class imbalance

Split features and target labels

Perform stratified trainâ€“test split

Train a baseline Logistic Regression model

Evaluate the model using multiple metrics

Handle class imbalance using SMOTE

Retrain the model and compare results

ğŸ“ˆ Evaluation Metrics

Accuracy alone is misleading for imbalanced datasets.
Therefore, the following metrics are used:

Precision

Recall

F1-Score

Confusion Matrix

ğŸ”¹ Recall is prioritized, because missing a fraudulent transaction is more costly than incorrectly flagging a legitimate one.

ğŸ§ª Handling Class Imbalance

To improve fraud detection performance, SMOTE (Synthetic Minority Over-sampling Technique) is applied to balance the dataset by generating synthetic fraud samples.

This significantly improves the modelâ€™s ability to detect fraudulent transactions.

ğŸ§° Technologies & Libraries Used

Python

NumPy

Pandas

Scikit-learn

Imbalanced-learn (SMOTE)

Matplotlib

Seaborn

ğŸ“Š Model Performance Visualization

To better understand the impact of handling class imbalance, confusion matrix visualizations are included before and after applying SMOTE.

ğŸ”¹ Before SMOTE (Imbalanced Dataset)

This confusion matrix shows the model performance on the original, highly imbalanced dataset.
It highlights how the model struggles to correctly identify fraudulent transactions due to class imbalance.

ğŸ”¹ After SMOTE (Balanced Dataset)

After applying SMOTE (Synthetic Minority Over-sampling Technique), the dataset becomes balanced.
This confusion matrix demonstrates a significant improvement in recall for fraudulent transactions.

ğŸ§  Key Observation

Before SMOTE:
High accuracy but very poor fraud detection (low recall)

After SMOTE:
Improved fraud detection with better recall and balanced learning

This comparison clearly shows why accuracy alone is misleading for imbalanced binary classification problems.


![Before SMOTE](figure1.png)
![After SMOTE](figure2.png)
